{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing the Model**\n",
    "\n",
    "1. Importing Required Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TestImageDataset, is a custom class of a PyTorch dataset designed to handle test images without annotations.\n",
    "    - Loads test images from the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TestImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.image_paths = sorted([os.path.join(root, fname) for fname in os.listdir(root) if fname.endswith(('.jpg', '.png'))])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the Test Dataset:\n",
    "    - Select a Random Subset of Test Images (20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Loading test dataset...\")\n",
    "test_dataset = TestImageDataset(\n",
    "    root='/kaggle/input/coco-2017-dataset/coco2017/test2017',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "random.seed(42)\n",
    "test_indices = random.sample(range(len(test_dataset)), 20)\n",
    "test_subset = torch.utils.data.Subset(test_dataset, test_indices)\n",
    "\n",
    "test_loader = DataLoader(test_subset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Displaying detection.\n",
    "    - Draw the predicted bounding boxes and labels on the input image.\n",
    "    - Filter Low-Confidence Predictions (draw bounding box on predictions above 50 percent confidence score)\n",
    "    - Add text label of class or category name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def draw_predictions(image, predictions, category_names, threshold=0.5):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box, label, score in zip(predictions['boxes'], predictions['labels'], predictions['scores']):\n",
    "        if score > threshold:\n",
    "            box = box.tolist()\n",
    "            label_text = category_names[label.item()]\n",
    "            draw.rectangle(box, outline=\"red\", width=2)\n",
    "            draw.text((box[0], box[1]), f\"{label_text} {score:.2f}\", fill=\"yellow\")\n",
    "    return image\n",
    "\n",
    "def filter_predictions(outputs, threshold=0.5):\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "        keep = output['scores'] > threshold\n",
    "        predictions.append({\n",
    "            'boxes': output['boxes'][keep],\n",
    "            'labels': output['labels'][keep],\n",
    "            'scores': output['scores'][keep],\n",
    "        })\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Helper functions to fix data:\n",
    "    - Reverting the normalization applied during preprocessing so that the image can be visualized correctly.\n",
    "    - Fixes invalid or inconsistent bounding box coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def denormalize(tensor, mean, std):\n",
    "    mean = torch.tensor(mean).view(3, 1, 1)\n",
    "    std = torch.tensor(std).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "os.makedirs(\"/kaggle/working/test_results\", exist_ok=True)\n",
    "\n",
    "def correct_bounding_box(box):\n",
    "    x0, y0, x1, y1 = box\n",
    "    x0, x1 = min(x0, x1), max(x0, x1)\n",
    "    y0, y1 = min(y0, y1), max(y0, y1)\n",
    "    return [x0, y0, x1, y1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Starting the Testing Process:\n",
    "   - Removing the batch dimension from the image tensor.\n",
    "   - Applying softmax to convert raw classification logits into probabilities.\n",
    "   - Filters predictions based on a confidence threshold greater than 50 percent.\n",
    "   - Reverting normalization applied during preprocessing to restore the image to its original color range.\n",
    "   - Converting into PIL image for visualization.\n",
    "   - Save the output image with bounding boxes.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Starting testing...\")\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (image_tensor, image_path) in enumerate(test_loader):\n",
    "       \n",
    "        image_tensor = image_tensor.squeeze(0).to(device)\n",
    "        \n",
    "        image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "        outputs = model(image_tensor)\n",
    "        class_logits, bbox_regressions = outputs\n",
    "\n",
    "        class_scores = torch.softmax(class_logits, dim=-1)\n",
    "        top_scores, top_labels = torch.max(class_scores[0], dim=-1)\n",
    "        filtered_boxes = bbox_regressions[0]\n",
    "\n",
    "        keep = top_scores > 0.5\n",
    "        top_scores = top_scores[keep]\n",
    "        top_labels = top_labels[keep]\n",
    "        filtered_boxes = filtered_boxes[keep]\n",
    "\n",
    "        denormalized_image = denormalize(image_tensor.squeeze(0).cpu(), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]).clamp(0, 1)\n",
    "        pil_image = transforms.ToPILImage()(denormalized_image)\n",
    "\n",
    "        draw = ImageDraw.Draw(pil_image)\n",
    "        for box, label, score in zip(filtered_boxes, top_labels, top_scores):\n",
    "            box = correct_bounding_box(box.cpu().tolist())\n",
    "            label_text = COCO_INSTANCE_CATEGORY_NAMES[label.item()]\n",
    "            score_text = f\"{score.item() * 100:.1f}%\"\n",
    "            draw.rectangle(box, outline=\"red\", width=2)\n",
    "            draw.text((box[0], box[1]), f\"{label_text}: {score_text}\", fill=\"yellow\")\n",
    "\n",
    "        output_path = f\"/kaggle/working/test_results/test_image_{i + 1}.jpg\"\n",
    "        pil_image.save(output_path)\n",
    "\n",
    "        print(f\"Processed and saved: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
